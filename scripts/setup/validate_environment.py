#!/usr/bin/env python3
"""
ç’°å¢ƒæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ±äº¬é«˜å°‚å‡ºå‰æˆæ¥­ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°åˆ†æç’°å¢ƒ

ä¸»è¦æ©Ÿèƒ½:
1. Pythonç’°å¢ƒãƒ»ä¾å­˜é–¢ä¿‚ã®æ¤œè¨¼
2. æ—¥æœ¬èªNLPç’°å¢ƒã®å‹•ä½œç¢ºèª
3. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒ»æ•´åˆæ€§ç¢ºèª
4. å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
5. åŸºæœ¬åˆ†ææ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

å®Ÿè¡Œæ–¹æ³•: python scripts/setup/validate_environment.py
"""

import sys
import os
import importlib
import subprocess
from pathlib import Path
import json
import traceback
from typing import List, Dict, Tuple
import warnings

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore')

class EnvironmentValidator:
    """ç’°å¢ƒæ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.results = {
            'python_version': {'status': False, 'details': ''},
            'packages': {'status': False, 'details': {}, 'failed': []},
            'japanese_nlp': {'status': False, 'details': ''},
            'data_files': {'status': False, 'details': {}, 'missing': []},
            'directories': {'status': False, 'details': {}},
            'basic_functionality': {'status': False, 'details': {}}
        }
        
        # å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
        self.required_packages = [
            ('pandas', 'pandas'),
            ('numpy', 'numpy'),
            ('scipy', 'scipy'),
            ('matplotlib', 'matplotlib.pyplot'),
            ('seaborn', 'seaborn'),
            ('sklearn', 'sklearn'),
            ('gensim', 'gensim'),
            ('janome', 'janome.tokenizer'),
            ('textblob', 'textblob'),
            ('wordcloud', 'wordcloud'),
            ('yaml', 'yaml'),
            ('pathlib', 'pathlib')
        ]
        
        # æ‹¡å¼µãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        self.optional_packages = [
            ('pingouin', 'pingouin'),
            ('plotly', 'plotly'),
            ('kaleido', 'kaleido'),
            ('statsmodels', 'statsmodels'),
            ('fugashi', 'fugashi'),
            ('unidic_lite', 'unidic_lite')
        ]
        
        # å¿…é ˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
        self.required_data_files = [
            'data/raw/comments.csv',
            'data/raw/q2_reasons_before.csv', 
            'data/raw/q2_reasons_after.csv'
        ]
        
        # å¿…é ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.required_directories = [
            'outputs/wordclouds',
            'outputs/sentiment_results',
            'outputs/topic_models',
            'outputs/vocabulary',
            'outputs/statistics',
            'logs',
            'config'
        ]
    
    def check_python_version(self) -> bool:
        """Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª"""
        print("ğŸ Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª...")
        
        version = sys.version_info
        version_str = f"{version.major}.{version.minor}.{version.micro}"
        
        if version.major == 3 and version.minor >= 8:
            self.results['python_version'] = {
                'status': True,
                'details': f"Python {version_str} - OK (3.8+ è¦ä»¶æº€ãŸã™)"
            }
            print(f"   âœ“ Python {version_str} - OK")
            return True
        else:
            self.results['python_version'] = {
                'status': False,
                'details': f"Python {version_str} - NG (3.8+ å¿…é ˆ)"
            }
            print(f"   âœ— Python {version_str} - NG (3.8+ å¿…é ˆ)")
            return False
    
    def check_packages(self) -> bool:
        """ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å­˜åœ¨ç¢ºèª"""
        print("\nğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª...")
        
        results = {}
        failed_packages = []
        
        # å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
        print("   å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:")
        for package_name, import_name in self.required_packages:
            status, details = self._check_single_package(package_name, import_name)
            results[package_name] = {'status': status, 'details': details, 'required': True}
            
            if status:
                print(f"     âœ“ {package_name} - {details}")
            else:
                print(f"     âœ— {package_name} - {details}")
                failed_packages.append(package_name)
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
        print("   ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:")
        for package_name, import_name in self.optional_packages:
            status, details = self._check_single_package(package_name, import_name)
            results[package_name] = {'status': status, 'details': details, 'required': False}
            
            if status:
                print(f"     âœ“ {package_name} - {details}")
            else:
                print(f"     â—‹ {package_name} - æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
        
        # çµæœä¿å­˜
        all_required_ok = len(failed_packages) == 0
        self.results['packages'] = {
            'status': all_required_ok,
            'details': results,
            'failed': failed_packages
        }
        
        return all_required_ok
    
    def _check_single_package(self, package_name: str, import_name: str) -> Tuple[bool, str]:
        """å€‹åˆ¥ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª"""
        try:
            module = importlib.import_module(import_name)
            version = getattr(module, '__version__', 'unknown')
            return True, version
        except ImportError as e:
            return False, f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def check_japanese_nlp(self) -> bool:
        """æ—¥æœ¬èªNLPç’°å¢ƒç¢ºèª"""
        print("\nğŸ—¾ æ—¥æœ¬èªNLPç’°å¢ƒç¢ºèª...")
        
        # janome ãƒ†ã‚¹ãƒˆ
        janome_status = self._test_janome()
        
        # MeCab ãƒ†ã‚¹ãƒˆï¼ˆã‚ã‚Œã°ï¼‰
        mecab_status = self._test_mecab()
        
        # spaCy/ginza ãƒ†ã‚¹ãƒˆ
        spacy_status = self._test_spacy_ginza()
        
        # ç·åˆåˆ¤å®š
        nlp_available = janome_status or mecab_status
        
        details = {
            'janome': janome_status,
            'mecab': mecab_status,
            'spacy_ginza': spacy_status,
            'primary_tokenizer': 'janome' if janome_status else 'mecab' if mecab_status else 'none'
        }
        
        self.results['japanese_nlp'] = {
            'status': nlp_available,
            'details': details
        }
        
        if nlp_available:
            print(f"   âœ“ æ—¥æœ¬èªNLPç’°å¢ƒ - åˆ©ç”¨å¯èƒ½ï¼ˆ{details['primary_tokenizer']}ï¼‰")
        else:
            print("   âœ— æ—¥æœ¬èªNLPç’°å¢ƒ - åˆ©ç”¨ä¸å¯")
            
        return nlp_available
    
    def _test_janome(self) -> bool:
        """janome ãƒ†ã‚¹ãƒˆ"""
        try:
            from janome.tokenizer import Tokenizer
            tokenizer = Tokenizer()
            tokens = list(tokenizer.tokenize("ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™"))
            if len(tokens) > 0:
                print("     âœ“ janome - æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒ³åŒ– OK")
                return True
            else:
                print("     âœ— janome - ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å¤±æ•—")
                return False
        except Exception as e:
            print(f"     âœ— janome - ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_mecab(self) -> bool:
        """MeCab ãƒ†ã‚¹ãƒˆ"""
        try:
            import MeCab
            tagger = MeCab.Tagger()
            result = tagger.parse("ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™")
            if result and len(result.strip()) > 0:
                print("     âœ“ MeCab - æ—¥æœ¬èªè§£æ OK")
                return True
            else:
                print("     âœ— MeCab - è§£æå¤±æ•—")
                return False
        except Exception as e:
            print(f"     â—‹ MeCab - æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆjanomeã§ä»£æ›¿å¯èƒ½ï¼‰")
            return False
    
    def _test_spacy_ginza(self) -> bool:
        """spaCy/ginza ãƒ†ã‚¹ãƒˆ"""
        try:
            import spacy
            # ginzaãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
            try:
                nlp = spacy.load("ja_ginza")
                doc = nlp("ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™")
                if len(doc) > 0:
                    print("     âœ“ spaCy/ginza - æ—¥æœ¬èªè§£æ OK")
                    return True
                else:
                    print("     âœ— spaCy/ginza - è§£æå¤±æ•—")
                    return False
            except OSError:
                print("     â—‹ spaCy/ginza - ãƒ¢ãƒ‡ãƒ«æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåŸºæœ¬æ©Ÿèƒ½ã«ã¯ä¸è¦ï¼‰")
                return False
        except Exception as e:
            print(f"     â—‹ spaCy/ginza - æœªåˆ©ç”¨å¯èƒ½ï¼ˆåŸºæœ¬æ©Ÿèƒ½ã«ã¯ä¸è¦ï¼‰")
            return False
    
    def check_data_files(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª"""
        print("\nğŸ“„ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª...")
        
        file_details = {}
        missing_files = []
        
        for file_path in self.required_data_files:
            path_obj = Path(file_path)
            
            if path_obj.exists():
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«åŸºæœ¬æƒ…å ±
                    size = path_obj.stat().st_size
                    
                    # CSVèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
                    import pandas as pd
                    df = pd.read_csv(file_path, encoding='utf-8')
                    
                    file_details[file_path] = {
                        'exists': True,
                        'size_bytes': size,
                        'records': len(df),
                        'columns': list(df.columns)
                    }
                    
                    print(f"   âœ“ {file_path} - {len(df)}ä»¶ã€{len(df.columns)}åˆ—")
                    
                except Exception as e:
                    file_details[file_path] = {
                        'exists': True,
                        'size_bytes': size,
                        'error': str(e)
                    }
                    print(f"   âš  {file_path} - ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã™ã‚‹ãŒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    
            else:
                file_details[file_path] = {'exists': False}
                missing_files.append(file_path)
                print(f"   âœ— {file_path} - ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹")
        
        all_files_ok = len(missing_files) == 0
        self.results['data_files'] = {
            'status': all_files_ok,
            'details': file_details,
            'missing': missing_files
        }
        
        return all_files_ok
    
    def check_directories(self) -> bool:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèªãƒ»ä½œæˆ"""
        print("\nğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª...")
        
        directory_details = {}
        
        for dir_path in self.required_directories:
            path_obj = Path(dir_path)
            
            if path_obj.exists():
                directory_details[dir_path] = {'exists': True, 'created': False}
                print(f"   âœ“ {dir_path} - å­˜åœ¨")
            else:
                try:
                    path_obj.mkdir(parents=True, exist_ok=True)
                    directory_details[dir_path] = {'exists': True, 'created': True}
                    print(f"   âœ“ {dir_path} - ä½œæˆ")
                except Exception as e:
                    directory_details[dir_path] = {'exists': False, 'error': str(e)}
                    print(f"   âœ— {dir_path} - ä½œæˆå¤±æ•—: {e}")
        
        self.results['directories'] = {
            'status': True,  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ä½œæˆå¯èƒ½ãªã®ã§OK
            'details': directory_details
        }
        
        return True
    
    def check_basic_functionality(self) -> bool:
        """åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ...")
        
        test_results = {}
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        test_results['data_loading'] = self._test_data_loading()
        
        # 2. å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆ
        test_results['visualization'] = self._test_visualization()
        
        # 3. çµ±è¨ˆè¨ˆç®—ãƒ†ã‚¹ãƒˆ
        test_results['statistics'] = self._test_statistics()
        
        # 4. ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ
        test_results['text_processing'] = self._test_text_processing()
        
        all_tests_ok = all(test_results.values())
        
        self.results['basic_functionality'] = {
            'status': all_tests_ok,
            'details': test_results
        }
        
        return all_tests_ok
    
    def _test_data_loading(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        try:
            import pandas as pd
            
            # æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
            test_data = pd.DataFrame({
                'text': ['ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™', 'ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿'],
                'class': [1.0, 2.0],
                'page_id': [1, 2]
            })
            
            # åŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆ
            assert len(test_data) == 2
            assert 'text' in test_data.columns
            
            print("     âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ - OK")
            return True
            
        except Exception as e:
            print(f"     âœ— ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ - ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_visualization(self) -> bool:
        """å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆ"""
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            import numpy as np
            
            # ç°¡å˜ãªãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
            fig, ax = plt.subplots(figsize=(6, 4))
            x = np.array([1, 2, 3])
            y = np.array([1, 4, 2])
            ax.plot(x, y)
            ax.set_title('Test Plot')
            
            # ä¿å­˜ãƒ†ã‚¹ãƒˆ
            test_path = 'outputs/test_plot.png'
            plt.savefig(test_path, dpi=150)
            plt.close()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            if Path(test_path).exists():
                Path(test_path).unlink()  # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                print("     âœ“ å¯è¦–åŒ– - OK")
                return True
            else:
                print("     âœ— å¯è¦–åŒ– - ä¿å­˜å¤±æ•—")
                return False
                
        except Exception as e:
            print(f"     âœ— å¯è¦–åŒ– - ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_statistics(self) -> bool:
        """çµ±è¨ˆè¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        try:
            import numpy as np
            from scipy import stats
            
            # åŸºæœ¬çµ±è¨ˆãƒ†ã‚¹ãƒˆ
            data1 = np.array([1, 2, 3, 4, 5])
            data2 = np.array([2, 3, 4, 5, 6])
            
            # tæ¤œå®š
            statistic, pvalue = stats.ttest_ind(data1, data2)
            
            # Mann-Whitney Uæ¤œå®š
            u_stat, u_pvalue = stats.mannwhitneyu(data1, data2, alternative='two-sided')
            
            # åŠ¹æœé‡è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            cohens_d = (np.mean(data2) - np.mean(data1)) / np.sqrt((np.std(data1)**2 + np.std(data2)**2) / 2)
            
            assert not np.isnan(pvalue)
            assert not np.isnan(cohens_d)
            
            print("     âœ“ çµ±è¨ˆè¨ˆç®— - OK")
            return True
            
        except Exception as e:
            print(f"     âœ— çµ±è¨ˆè¨ˆç®— - ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_text_processing(self) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        try:
            from janome.tokenizer import Tokenizer
            
            # æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ†ã‚¹ãƒˆ
            tokenizer = Tokenizer()
            text = "ã¿ãæ±ã«ãƒŠãƒˆãƒªã‚¦ãƒ ãŒå…¥ã£ã¦ã„ã‚‹ã‹ã‚‰"
            tokens = list(tokenizer.tokenize(text))
            
            # èªå½™æŠ½å‡ºãƒ†ã‚¹ãƒˆ
            token_texts = [token.surface for token in tokens]
            contains_miso = any('ã¿ã' in token for token in token_texts)
            contains_natrium = any('ãƒŠãƒˆãƒªã‚¦ãƒ ' in token for token in token_texts)
            
            assert len(tokens) > 0
            
            print("     âœ“ ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç† - OK")
            return True
            
        except Exception as e:
            print(f"     âœ— ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç† - ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_report(self) -> Dict:
        """ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        overall_status = all([
            self.results['python_version']['status'],
            self.results['packages']['status'],
            self.results['japanese_nlp']['status'],
            self.results['data_files']['status'],
            self.results['directories']['status'],
            self.results['basic_functionality']['status']
        ])
        
        report = {
            'overall_status': overall_status,
            'timestamp': str(Path(__file__).stat().st_mtime),  # ç°¡æ˜“ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            'checks': self.results,
            'recommendations': self._generate_recommendations()
        }
        
        return report
    
    def _generate_recommendations(self) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        if not self.results['python_version']['status']:
            recommendations.append("Python 3.8ä»¥ä¸Šã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        
        if self.results['packages']['failed']:
            failed_packages = ', '.join(self.results['packages']['failed'])
            recommendations.append(f"å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: {failed_packages}")
        
        if not self.results['japanese_nlp']['status']:
            recommendations.append("æ—¥æœ¬èªNLPç’°å¢ƒã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼ˆjanomeæ¨å¥¨ï¼‰")
        
        if self.results['data_files']['missing']:
            missing_files = ', '.join(self.results['data_files']['missing'])
            recommendations.append(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„: {missing_files}")
        
        if not self.results['basic_functionality']['status']:
            recommendations.append("åŸºæœ¬æ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¾å­˜é–¢ä¿‚ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        if not recommendations:
            recommendations.append("å…¨ã¦ã®ç’°å¢ƒç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸã€‚åˆ†æã‚’é–‹å§‹ã§ãã¾ã™ï¼")
        
        return recommendations
    
    def save_report(self, output_path: str = "outputs/environment_validation_report.json"):
        """ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        report = self.generate_report()
        
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_path}")
    
    def run_validation(self) -> bool:
        """ãƒ¡ã‚¤ãƒ³æ¤œè¨¼å®Ÿè¡Œ"""
        print("="*60)
        print("ğŸ” æ±äº¬é«˜å°‚ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°ç’°å¢ƒæ¤œè¨¼")
        print("="*60)
        
        try:
            # å„æ¤œè¨¼å®Ÿè¡Œ
            python_ok = self.check_python_version()
            packages_ok = self.check_packages()
            nlp_ok = self.check_japanese_nlp()
            data_ok = self.check_data_files()
            dirs_ok = self.check_directories()
            func_ok = self.check_basic_functionality()
            
            # ç·åˆçµæœ
            overall_ok = all([python_ok, packages_ok, nlp_ok, data_ok, dirs_ok, func_ok])
            
            # çµæœè¡¨ç¤º
            print("\n" + "="*60)
            print("ğŸ æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
            print("="*60)
            
            status_icon = "âœ…" if overall_ok else "âŒ"
            print(f"{status_icon} ç·åˆçµæœ: {'æˆåŠŸ' if overall_ok else 'å¤±æ•—'}")
            
            # æ¨å¥¨äº‹é …è¡¨ç¤º
            recommendations = self._generate_recommendations()
            print("\nğŸ“‹ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            self.save_report()
            
            if overall_ok:
                print("\nğŸš€ ç’°å¢ƒæº–å‚™å®Œäº†ï¼åˆ†æã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
                print("   æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: python scripts/analysis/02_vocabulary_analysis.py")
            else:
                print("\nâš ï¸  ç’°å¢ƒã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¸Šè¨˜æ¨å¥¨äº‹é …ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            return overall_ok
            
        except Exception as e:
            print(f"\nâŒ æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"è©³ç´°: {traceback.format_exc()}")
            return False


if __name__ == "__main__":
    validator = EnvironmentValidator()
    success = validator.run_validation()
    sys.exit(0 if success else 1)