#!/usr/bin/env python3
"""
æ—¥æœ¬èªãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®šãƒ„ãƒ¼ãƒ«
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ•ã‚©ãƒ³ãƒˆãƒ»è¨­å®šã‚’èª¿æ•´å¯èƒ½ãªWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

å®Ÿè¡Œæ–¹æ³•: python wordcloud_app/app.py
ã‚¢ã‚¯ã‚»ã‚¹: http://localhost:5000
"""

import os
import sys
import json
import base64
import io
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
from wordcloud import WordCloud
import matplotlib
matplotlib.use('Agg')  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®šï¼ˆGUIä¸è¦ï¼‰
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import logging
import pandas as pd
from janome.tokenizer import Tokenizer
from matplotlib.colors import LinearSegmentedColormap

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.append(str(project_root))

app = Flask(__name__)
CORS(app)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WordCloudGenerator:
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.fonts_dir = project_root / "fonts"
        self.load_available_fonts()
        self.load_sample_texts()
        self.tokenizer = Tokenizer()
        self.create_custom_colormaps()
        
        # æ—¥æœ¬èªã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰
        self.stop_words = set([
            'ã¦', 'ã«', 'ã‚’', 'ã¯', 'ãŒ', 'ã§', 'ã¨', 'ã—', 'ã‚Œ', 'ã•', 'ã‚ã‚‹', 'ã„ã‚‹', 
            'ã‚‚', 'ã™ã‚‹', 'ã‹ã‚‰', 'ãª', 'ã“ã¨', 'ã§ã™', 'ã ', 'ãŸ', 'ã—ãŸ', 'ã®', 'ã‚ˆã†',
            'ã‚Œã‚‹', 'ãã‚‹', 'ã‚„', 'ãã‚Œ', 'ãã†', 'ãªã„', 'ã‹', 'ã®ã§', 'ã‚ˆ', 'ã¦ã‚‹',
            'ã‚‚ã®', 'ã¿', 'ã¾ãŸ', 'ãã®', 'ã‚ã‚Š', 'ã', 'ã„', 'ã†', 'ã®ã¯', 'ã‚“',
            'ã®ãŒ', 'ã‚‚ã‚“', 'ã©ã†', 'ãªã©', 'ãƒã‚¹', 'ã€‚', 'ã€', 'ï¼ˆ', 'ï¼‰', '(', ')',
            'ã‚ˆã‚Š', 'ã¸', 'ã¾ã§', 'ã‹ã‚‰', 'ã¾ãŸ', 'ã‚‚', 'ãŠ', 'ã¿ãªã•ã‚“', 'ä»Šæ—¥',
            'ã‚ã‚ŠãŒã¨ã†', 'ã”ã–ã„', 'ã¾ã—ãŸ', 'ã¦ãã‚Œ', 'ãã‚Œã‚‹', 'ã¦ãã‚Œã‚‹',
            'ãã ã•ã‚Š', 'ãã ã•ã„', 'ã¾ã›', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„',
            'æ±äº¬é«˜å°‚', 'ã¿ãªã•ã‚“', 'æœ¬å½“', 'ä¸€ç•ª', 'æˆæ¥­', 'ã§ã', 'ã„ã£',
            'ãŠã‚‚ã—ã‚', 'ã™ã”', 'ã‚ˆã‹ã£', 'ã‚ˆã‚Š', 'ã“ã¨', 'ä»Šæ—¥', 'ãã†', 'ãª',
            'ã¦', 'ã‚‹', 'ã‚ˆã†', 'ã«', 'ã§', 'ã¨', 'ã‹ã‚‰', 'ã€‚', 'ã€', 'ãŒ',
            'ãƒŸãƒ³ãƒ', 'ã‚«ãƒ«ã‚·ã‚¦ãƒ ', 'ãƒãƒªã‚¦ãƒ ', 'ãƒªãƒã‚¦ãƒ ', 'ãƒ›ã‚¦é…¸',
            'ãƒ¦ã‚­', 'ã‚¹ã‚±ãƒƒãƒ', 'ã„ã†', 'ã¹ã', 'ã ã£', 'ã¤ã„', 'ã£ãŸ',
            'ã¨ã£', 'ãŠã‚‚ã—ã‚ã„', 'ãã‚Œã„', 'ã™ã”ã„', 'ãªã‚‹', 'ã¿ã‚‹', 'ã„ã',
            'ã‚Œ', 'ãªã‚Š', 'ã‚„ã£', 'ãŸã„', 'ã„ã„', 'ãã‚Œ', 'ãŠ'
        ])
    
    def create_custom_colormaps(self):
        """ã‚ªãƒ¬ãƒ³ã‚¸ã¨é’ã®ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’ä½œæˆ"""
        # ã‚ªãƒ¬ãƒ³ã‚¸ã‹ã‚‰é’ã¸ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        colors1 = ['#FF6B00', '#FF8C00', '#FFA500', '#FFB84D', '#FFD700', 
                  '#87CEEB', '#4682B4', '#1E90FF', '#0066CC', '#003D7A']
        n_bins = 100
        self.orange_blue = LinearSegmentedColormap.from_list('orange_blue', colors1, N=n_bins)
        
        # é’ã‹ã‚‰ã‚ªãƒ¬ãƒ³ã‚¸ã¸ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        colors2 = ['#003D7A', '#0066CC', '#1E90FF', '#4682B4', '#87CEEB',
                  '#FFD700', '#FFB84D', '#FFA500', '#FF8C00', '#FF6B00']
        self.blue_orange = LinearSegmentedColormap.from_list('blue_orange', colors2, N=n_bins)
        
        # ã‚ªãƒ¬ãƒ³ã‚¸ãƒ»é’ã®ãƒãƒ©ãƒ³ã‚¹ã‚«ãƒ©ãƒ¼
        colors3 = ['#FF6B00', '#FF8C00', '#FFA500', '#FFD700', '#FFFF00',
                  '#FFFFFF', '#87CEEB', '#4682B4', '#1E90FF', '#003D7A']
        self.orange_white_blue = LinearSegmentedColormap.from_list('orange_white_blue', colors3, N=n_bins)
        
        # æ±äº¬é«˜å°‚ã‚«ãƒ©ãƒ¼ï¼ˆæš–è‰²ç³»ï¼‰
        colors4 = ['#FF4500', '#FF6347', '#FF7F50', '#FFA07A', '#FFB347',
                  '#FFD700', '#FFA500', '#FF8C00', '#FF6B00', '#FF4500']
        self.tokyo_kosen_warm = LinearSegmentedColormap.from_list('tokyo_kosen_warm', colors4, N=n_bins)
        
        # æ±äº¬é«˜å°‚ã‚«ãƒ©ãƒ¼ï¼ˆå¯’è‰²ç³»ï¼‰
        colors5 = ['#000080', '#0000CD', '#0000FF', '#1E90FF', '#4169E1',
                  '#4682B4', '#5F9EA0', '#6495ED', '#87CEEB', '#ADD8E6']
        self.tokyo_kosen_cool = LinearSegmentedColormap.from_list('tokyo_kosen_cool', colors5, N=n_bins)
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’è¾æ›¸ã§ä¿æŒ
        self.custom_colormaps = {
            'orange_blue': self.orange_blue,
            'blue_orange': self.blue_orange,
            'orange_white_blue': self.orange_white_blue,
            'tokyo_kosen_warm': self.tokyo_kosen_warm,
            'tokyo_kosen_cool': self.tokyo_kosen_cool
        }
        
    def load_available_fonts(self):
        """åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿"""
        font_list_path = self.fonts_dir / "font_list.json"
        
        if font_list_path.exists():
            with open(font_list_path, 'r', encoding='utf-8') as f:
                self.available_fonts = json.load(f)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆ
            self.available_fonts = {
                "default": {
                    "name": "Default",
                    "path": None,
                    "description": "ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"
                }
            }
        
        logger.info(f"åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆæ•°: {len(self.available_fonts)}")
    
    def load_sample_texts(self):
        """å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
            data_path = project_root / "data" / "processed" / "all_text_corpus.csv"
            if data_path.exists():
                df = pd.read_csv(data_path)
                
                # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
                comments_text = ' '.join(df[df['category'] == 'æ„Ÿæƒ³æ–‡']['text'].tolist())
                before_text = ' '.join(df[df['category'] == 'Q2ç†ç”±_æˆæ¥­å‰']['text'].tolist())
                after_text = ' '.join(df[df['category'] == 'Q2ç†ç”±_æˆæ¥­å¾Œ']['text'].tolist())
                all_text = ' '.join(df['text'].tolist())
                
                self.sample_texts = {
                    "all_responses": {
                        "name": "å…¨å›ç­”ï¼ˆçµ±åˆï¼‰",
                        "text": all_text
                    },
                    "comments": {
                        "name": "æ„Ÿæƒ³æ–‡ã®ã¿",
                        "text": comments_text
                    },
                    "q2_before": {
                        "name": "æˆæ¥­å‰ï¼ˆãªãœã—ã‚‡ã£ã±ã„ï¼Ÿï¼‰",
                        "text": before_text
                    },
                    "q2_after": {
                        "name": "æˆæ¥­å¾Œï¼ˆãªãœã—ã‚‡ã£ã±ã„ï¼Ÿï¼‰",
                        "text": after_text
                    },
                    "custom": {
                        "name": "ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆ",
                        "text": ""
                    }
                }
                logger.info("å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
                self._load_default_texts()
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self._load_default_texts()
    
    def _load_default_texts(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ"""
        self.sample_texts = {
            "science_education": {
                "name": "ç§‘å­¦æ•™è‚²ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰",
                "text": """æ±äº¬å·¥æ¥­å¤§å­¦ å‡ºå‰æˆæ¥­ ãƒŠãƒˆãƒªã‚¦ãƒ  å¡©åŒ–ãƒŠãƒˆãƒªã‚¦ãƒ  ç‚è‰²åå¿œ å®Ÿé¨“ è¦³å¯Ÿ ç§‘å­¦ å­¦ç¿’ 
                         é¢ç™½ã„ ã™ã”ã„ ãã‚Œã„ ç™ºè¦‹ ç†è§£ çŸ¥è­˜ ç ”ç©¶ ä½“é¨“ æ„Ÿå‹• ã³ã£ãã‚Š"""
            },
            "custom": {
                "name": "ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆ",
                "text": ""
            }
        }
    
    def tokenize_japanese(self, text):
        """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²"""
        # å˜èªã‚’æŠ½å‡ºï¼ˆåè©ã€å‹•è©ã€å½¢å®¹è©ã€å‰¯è©ã®ã¿ï¼‰
        words = []
        for token in self.tokenizer.tokenize(text):
            part_of_speech = token.part_of_speech.split(',')[0]
            if part_of_speech in ['åè©', 'å‹•è©', 'å½¢å®¹è©', 'å‰¯è©']:
                # åŸºæœ¬å½¢ã‚’å–å¾—
                base_form = token.base_form
                word = base_form if base_form != '*' else token.surface
                
                # 2æ–‡å­—ä»¥ä¸Šã‹ã¤ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã§ãªã„å˜èªã®ã¿ã‚’è¿½åŠ 
                if len(word) >= 2 and word not in self.stop_words:
                    words.append(word)
        return ' '.join(words)
    
    def generate_wordcloud(self, config):
        """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            text_key = config.get('text_source', 'all_responses')
            if text_key == 'custom':
                text = config.get('custom_text', '')
            else:
                text = self.sample_texts.get(text_key, {}).get('text', '')
            
            if not text.strip():
                return None, "ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"
            
            # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²
            tokenized_text = self.tokenize_japanese(text)
            
            # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            font_key = config.get('font', 'default')
            font_info = self.available_fonts.get(font_key, {})
            font_path = font_info.get('path')
            
            # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
            if font_path and not Path(font_path).is_absolute():
                font_path = str(project_root / font_path)
            
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®š
            background_color = config.get('background_color', 'lightgray')
            # èƒŒæ™¯è‰²ãŒç™½ã®å ´åˆã¯ã‚°ãƒ¬ãƒ¼ã«å¤‰æ›´
            if background_color == 'white':
                background_color = 'lightgray'
            
            # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’é¸æŠ
            colormap_name = config.get('colormap', 'orange_blue')
            colormap = self.custom_colormaps.get(colormap_name, colormap_name)
            
            wordcloud_config = {
                'width': config.get('width', 800),
                'height': config.get('height', 400),
                'background_color': background_color,
                'max_words': config.get('max_words', 100),
                'colormap': colormap,
                'relative_scaling': config.get('relative_scaling', 0.5),
                'min_font_size': config.get('min_font_size', 10),
                'max_font_size': config.get('max_font_size', 100),
                'prefer_horizontal': config.get('prefer_horizontal', 0.7),
                'collocations': False,
                'regexp': r'[\w]+',
                'include_numbers': False,
                'normalize_plurals': False,
                'stopwords': self.stop_words
            }
            
            if font_path:
                wordcloud_config['font_path'] = font_path
            
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
            wordcloud = WordCloud(**wordcloud_config).generate(tokenized_text)
            
            # ç”»åƒå¤‰æ›
            plt.figure(figsize=(12, 6))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.tight_layout(pad=0)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            img_buffer = io.BytesIO()
            plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            img_buffer.seek(0)
            plt.close()
            
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            
            return img_base64, None
            
        except Exception as e:
            logger.error(f"ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None, str(e)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
generator = WordCloudGenerator()

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return render_template('index.html')

@app.route('/api/fonts')
def get_fonts():
    """åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆä¸€è¦§å–å¾—"""
    return jsonify({
        'fonts': generator.available_fonts,
        'count': len(generator.available_fonts)
    })

@app.route('/api/sample-texts')
def get_sample_texts():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆä¸€è¦§å–å¾—"""
    return jsonify({
        'texts': generator.sample_texts
    })

@app.route('/api/generate', methods=['POST'])
def generate_wordcloud():
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”ŸæˆAPI"""
    try:
        config = request.json
        
        img_base64, error = generator.generate_wordcloud(config)
        
        if error:
            return jsonify({
                'success': False,
                'error': error
            }), 400
        
        return jsonify({
            'success': True,
            'image': img_base64,
            'config': config
        })
        
    except Exception as e:
        logger.error(f"API ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/export-config', methods=['POST'])
def export_config():
    """è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        config = request.json
        
        # è¨­å®šã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        exports_dir = project_root / "outputs" / "wordcloud_configs"
        exports_dir.mkdir(parents=True, exist_ok=True)
        
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"wordcloud_config_{timestamp}.json"
        config_path = exports_dir / filename
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'filename': filename,
            'path': str(config_path)
        })
        
    except Exception as e:
        logger.error(f"è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/presets')
def get_presets():
    """ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®šå–å¾—"""
    presets = {
        "production": {
            "name": "æœ¬ç•ªç”¨ï¼ˆæ±äº¬é«˜å°‚ï¼‰",
            "config": {
                "text_source": "all_responses",
                "width": 1000,
                "height": 600,
                "background_color": "lightgray",
                "max_words": 60,
                "colormap": "orange_blue",
                "relative_scaling": 0.6,
                "min_font_size": 16,
                "max_font_size": 90,
                "prefer_horizontal": 0.8,
                "collocations": False
            }
        },
        "comments_only": {
            "name": "æ„Ÿæƒ³æ–‡ã®ã¿",
            "config": {
                "text_source": "comments",
                "width": 800,
                "height": 400,
                "background_color": "lightgray",
                "max_words": 50,
                "colormap": "tokyo_kosen_warm",
                "relative_scaling": 0.5,
                "min_font_size": 14,
                "max_font_size": 70,
                "prefer_horizontal": 0.8,
                "collocations": False
            }
        },
        "before_after": {
            "name": "æˆæ¥­å‰å¾Œæ¯”è¼ƒ",
            "config": {
                "text_source": "q2_after",
                "width": 900,
                "height": 500,
                "background_color": "lightgray",
                "max_words": 40,
                "colormap": "blue_orange",
                "relative_scaling": 0.5,
                "min_font_size": 16,
                "max_font_size": 80,
                "prefer_horizontal": 0.7,
                "collocations": False
            }
        },
        "academic": {
            "name": "å­¦è¡“ç™ºè¡¨ç”¨",
            "config": {
                "width": 1200,
                "height": 800,
                "background_color": "lightgray",
                "max_words": 50,
                "colormap": "tokyo_kosen_cool",
                "relative_scaling": 0.3,
                "min_font_size": 20,
                "max_font_size": 120,
                "prefer_horizontal": 0.8,
                "collocations": False
            }
        },
        "colorful": {
            "name": "ã‚«ãƒ©ãƒ•ãƒ«",
            "config": {
                "width": 800,
                "height": 600,
                "background_color": "darkgray",
                "max_words": 150,
                "colormap": "orange_white_blue",
                "relative_scaling": 0.7,
                "min_font_size": 8,
                "max_font_size": 80,
                "prefer_horizontal": 0.5,
                "collocations": False
            }
        },
        "minimal": {
            "name": "ãƒŸãƒ‹ãƒãƒ«",
            "config": {
                "width": 600,
                "height": 300,
                "background_color": "#f0f0f0",
                "max_words": 30,
                "colormap": "tokyo_kosen_warm",
                "relative_scaling": 0.2,
                "min_font_size": 15,
                "max_font_size": 60,
                "prefer_horizontal": 0.9,
                "collocations": False
            }
        }
    }
    
    return jsonify({'presets': presets})

@app.route('/api/colormaps')
def get_colormaps():
    """åˆ©ç”¨å¯èƒ½ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—å–å¾—"""
    import matplotlib.cm as cm
    
    # æ¨å¥¨ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼ˆã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ã‚’å…ˆé ­ã«ï¼‰
    recommended_maps = [
        'orange_blue', 'blue_orange', 'orange_white_blue', 
        'tokyo_kosen_warm', 'tokyo_kosen_cool',
        'Oranges', 'Blues', 'RdBu', 'BuOr', 'PuOr', 'coolwarm',
        'Set2', 'Set3', 'Pastel1', 'Pastel2',
        'viridis', 'plasma', 'inferno', 'magma',
        'copper', 'autumn', 'winter', 'spring', 'summer',
        'tab10', 'tab20', 'gray'
    ]
    
    return jsonify({'colormaps': recommended_maps})

if __name__ == '__main__':
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿
    logs_dir = project_root / "logs"
    logs_dir.mkdir(exist_ok=True)
    
    print("ğŸŒ¨ æ±äº¬é«˜å°‚ å‡ºå‰æˆæ¥­åˆ†æ - ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    print(f"ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹URL: http://localhost:5001")
    print(f"ğŸ“ ãƒ•ã‚©ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {generator.fonts_dir}")
    print(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆæ•°: {len(generator.available_fonts)}")
    print("ğŸ”¥ ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—: ã‚ªãƒ¬ãƒ³ã‚¸+é’ç³»")
    print("ğŸ¤– æ—¥æœ¬èªå½¢æ…‹ç´ è§£æ: Janomeä½¿ç”¨")
    print("=" * 60)
    
    # Flaskã‚¢ãƒ—ãƒªå®Ÿè¡Œ
    app.run(debug=True, host='0.0.0.0', port=5001)