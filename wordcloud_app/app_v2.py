#!/usr/bin/env python3
"""
æ—¥æœ¬èªãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®šãƒ„ãƒ¼ãƒ« Ver.2 - å˜èªé™¤å¤–ãƒ†ã‚¹ãƒˆç”¨
å›ºå®šãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£æ”¹å–„ç‰ˆ
ãƒãƒ¼ãƒˆ5002ã§å‹•ä½œ

å®Ÿè¡Œæ–¹æ³•: python wordcloud_app/app_v2.py
ã‚¢ã‚¯ã‚»ã‚¹: http://localhost:5002
"""

import os
import sys
import json
import base64
import io
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
from wordcloud import WordCloud
import matplotlib
matplotlib.use('Agg')  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®šï¼ˆGUIä¸è¦ï¼‰
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from PIL import Image
import numpy as np
import logging
import pandas as pd
from janome.tokenizer import Tokenizer
from matplotlib.colors import ListedColormap
from collections import Counter
from scipy import stats
import math

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.append(str(project_root))

app = Flask(__name__)
CORS(app)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DifferenceWordCloudGenerator:
    """å·®åˆ†ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_generator):
        """ãƒ™ãƒ¼ã‚¹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‹ã‚‰æ©Ÿèƒ½ã‚’ç¶™æ‰¿"""
        self.base_generator = base_generator
        self.create_difference_colormaps()
        
        # ç§‘å­¦ç”¨èªãƒªã‚¹ãƒˆï¼ˆæ•™è‚²åŠ¹æœæ¸¬å®šç”¨ï¼‰
        self.science_terms = {
            'basic': ['å¡©', 'é£Ÿå¡©', 'å¡©åˆ†'],
            'intermediate': ['ãƒŠãƒˆãƒªã‚¦ãƒ ', 'å¡©åŒ–ãƒŠãƒˆãƒªã‚¦ãƒ '],
            'advanced': ['Na', 'NaCl', 'ã‚¤ã‚ªãƒ³', 'Na+']
        }
    
    def create_difference_colormaps(self):
        """å·®åˆ†å¯è¦–åŒ–ç”¨ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ä½œæˆï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼æº–æ‹ ï¼‰"""
        # é€šå¸¸ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã®ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼ã‚’åŸºæº–ã«ã™ã‚‹
        base_orange = self.base_generator.ACCESSIBLE_COLORS['orange']  # #d06500
        base_blue = self.base_generator.ACCESSIBLE_COLORS['blue']      # #0066cc
        base_brown = self.base_generator.ACCESSIBLE_COLORS['brown']    # #331a00
        
        self.difference_colors = {
            # å¢—åŠ èªï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ç³»ï¼‰- ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼æº–æ‹ 
            'increase_large': base_brown,    # å¤§å¹…å¢—åŠ ï¼ˆãƒ€ãƒ¼ã‚¯ãƒ–ãƒ©ã‚¦ãƒ³ï¼‰
            'increase_medium': base_orange,  # ä¸­ç¨‹åº¦å¢—åŠ ï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
            'increase_small': '#ff9800',     # è»½å¾®å¢—åŠ ï¼ˆæ˜ã‚‹ã„ã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
            
            # æ¸›å°‘èªï¼ˆãƒ–ãƒ«ãƒ¼ç³»ï¼‰- ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼æº–æ‹ 
            'decrease_large': base_blue,     # å¤§å¹…æ¸›å°‘ï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ãƒ–ãƒ«ãƒ¼ï¼‰
            'decrease_medium': '#1976d2',    # ä¸­ç¨‹åº¦æ¸›å°‘ï¼ˆå°‘ã—æ˜ã‚‹ã„é’ï¼‰
            'decrease_small': '#64b5f6',     # è»½å¾®æ¸›å°‘ï¼ˆè–„ã„é’ï¼‰
            
            # å…±é€šãƒ»ç§‘å­¦ç”¨èª
            'common': '#757575',             # å¤‰åŒ–ãªã—ï¼ˆä¸­é–“ã‚°ãƒ¬ãƒ¼ï¼‰
            'science_highlight': base_brown  # ç§‘å­¦ç”¨èªï¼ˆçµ±ä¸€æ„Ÿã®ãŸã‚ãƒ–ãƒ©ã‚¦ãƒ³ï¼‰
        }
        
        # å·®åˆ†ç”¨ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ä½œæˆ
        self.difference_colormaps = {
            'difference_standard': ListedColormap([
                self.difference_colors['decrease_large'],
                self.difference_colors['decrease_medium'], 
                self.difference_colors['decrease_small'],
                self.difference_colors['common'],
                self.difference_colors['increase_small'],
                self.difference_colors['increase_medium'],
                self.difference_colors['increase_large']
            ]),
            'science_focused': ListedColormap([
                self.difference_colors['decrease_medium'],
                self.difference_colors['common'],
                self.difference_colors['increase_medium'],
                self.difference_colors['science_highlight']
            ])
        }
    
    def get_matplotlib_font_props(self, font_path):
        """matplotlibç”¨ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å–å¾—"""
        # ãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if font_path and Path(font_path).exists():
            try:
                return fm.FontProperties(fname=font_path)
            except Exception as e:
                logger.warning(f"ãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è©¦ã™
        fonts_dir = self.base_generator.fonts_dir
        default_fonts = [
            fonts_dir / "ipaexg.ttf",
            fonts_dir / "ipag.ttf", 
            fonts_dir / "NotoSansJP-Regular.otf",
            fonts_dir / "HannariMincho-Regular.otf"
        ]
        
        for default_font in default_fonts:
            if default_font.exists():
                try:
                    logger.info(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨: {default_font}")
                    return fm.FontProperties(fname=str(default_font))
                except Exception as e:
                    logger.warning(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                    continue
        
        logger.warning("åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    def calculate_word_frequencies(self, text, excluded_words=None):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å˜èªé »åº¦ã‚’è¨ˆç®—"""
        tokenized_text = self.base_generator.tokenize_japanese(text, excluded_words)
        words = tokenized_text.split()
        return Counter(words)
    
    def calculate_difference_statistics(self, base_freq, compare_freq):
        """å·®åˆ†çµ±è¨ˆã‚’è¨ˆç®—"""
        all_words = set(base_freq.keys()) | set(compare_freq.keys())
        
        statistics = {
            'total_words_base': len(base_freq),
            'total_words_compare': len(compare_freq),
            'unique_words_base': len(set(base_freq.keys())),
            'unique_words_compare': len(set(compare_freq.keys())),
            'new_words': [],      # æ–°å‡ºç¾èª
            'lost_words': [],     # æ¶ˆå¤±èª
            'increased_words': [],  # å¢—åŠ èª
            'decreased_words': [],  # æ¸›å°‘èª
            'science_term_changes': {}  # ç§‘å­¦ç”¨èªå¤‰åŒ–
        }
        
        for word in all_words:
            base_count = base_freq.get(word, 0)
            compare_count = compare_freq.get(word, 0)
            
            if base_count == 0 and compare_count > 0:
                statistics['new_words'].append((word, compare_count))
            elif base_count > 0 and compare_count == 0:
                statistics['lost_words'].append((word, base_count))
            elif compare_count > base_count:
                statistics['increased_words'].append((word, compare_count - base_count))
            elif compare_count < base_count:
                statistics['decreased_words'].append((word, base_count - compare_count))
        
        # ç§‘å­¦ç”¨èªå¤‰åŒ–ã®åˆ†æ
        for level, terms in self.science_terms.items():
            for term in terms:
                base_count = base_freq.get(term, 0)
                compare_count = compare_freq.get(term, 0)
                if base_count > 0 or compare_count > 0:
                    statistics['science_term_changes'][term] = {
                        'level': level,
                        'base': base_count,
                        'compare': compare_count,
                        'change': compare_count - base_count
                    }
        
        # ã‚½ãƒ¼ãƒˆï¼ˆé »åº¦é †ï¼‰
        statistics['new_words'].sort(key=lambda x: x[1], reverse=True)
        statistics['lost_words'].sort(key=lambda x: x[1], reverse=True)
        statistics['increased_words'].sort(key=lambda x: x[1], reverse=True)
        statistics['decreased_words'].sort(key=lambda x: x[1], reverse=True)
        
        return statistics
    
    def generate_difference_frequencies(self, base_freq, compare_freq, config):
        """å·®åˆ†é »åº¦è¾æ›¸ã‚’ç”Ÿæˆï¼ˆæ–¹å‘æ€§é‡è¦–ç‰ˆï¼‰"""
        all_words = set(base_freq.keys()) | set(compare_freq.keys())
        
        # è¨­å®šã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        calculation_method = config.get('calculation_method', 'frequency_difference')
        min_occurrence = config.get('min_occurrence', 1)
        min_difference = config.get('min_difference', 0.01)
        
        # åˆ†æç”¨ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
        self.word_analysis = {}
        difference_freq = {}
        
        for word in all_words:
            base_count = base_freq.get(word, 0)
            compare_count = compare_freq.get(word, 0)
            
            # æœ€å°å‡ºç¾å›æ•°ãƒ•ã‚£ãƒ«ã‚¿
            if max(base_count, compare_count) < min_occurrence:
                continue
            
            # å·®åˆ†è¨ˆç®—ï¼ˆæ–¹å‘æ€§ä¿æŒï¼‰
            if calculation_method == 'frequency_difference':
                diff = compare_count - base_count
            elif calculation_method == 'relative_difference':
                if base_count == 0:
                    diff = compare_count if compare_count > 0 else 0
                else:
                    diff = (compare_count - base_count) / base_count
            elif calculation_method == 'log_ratio':
                if base_count == 0 or compare_count == 0:
                    diff = compare_count - base_count
                else:
                    diff = math.log(compare_count / base_count)
            else:
                diff = compare_count - base_count
            
            # æœ€å°å·®åˆ†ãƒ•ã‚£ãƒ«ã‚¿
            if abs(diff) >= min_difference:
                # å˜èªåˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆæ–¹å‘æ€§æƒ…å ±å«ã‚€ï¼‰
                self.word_analysis[word] = {
                    'diff': diff,
                    'base': base_count,
                    'compare': compare_count,
                    'direction': 'increase' if diff > 0 else 'decrease' if diff < 0 else 'stable',
                    'magnitude': abs(diff)
                }
                
                # ç§‘å­¦ç”¨èªã®ç‰¹åˆ¥å‡¦ç†
                is_science_term = False
                if config.get('science_highlight', False):
                    for level, terms in self.science_terms.items():
                        if word in terms:
                            self.word_analysis[word]['science_level'] = level
                            is_science_term = True
                            break
                
                # æ–¹å‘æ€§ã«åŸºã¥ãå¼·èª¿è¨ˆç®—
                if calculation_method == 'frequency_difference':
                    # æ–°å‡ºç¾èªã¯å¤§å¹…å¼·èª¿ã€æ¸›å°‘èªã¯æ§ãˆã‚
                    if base_count == 0 and compare_count > 0:  # æ–°å‡ºç¾èª
                        weight = compare_count * 3  # 3å€å¼·èª¿
                    elif compare_count == 0 and base_count > 0:  # æ¶ˆå¤±èª
                        weight = base_count * 0.5  # æ§ãˆã‚è¡¨ç¤º
                    else:
                        weight = abs(diff) * 2  # é€šå¸¸ã®å¤‰åŒ–
                elif calculation_method == 'relative_difference':
                    # ç›¸å¯¾å¤‰åŒ–ç‡ã«åŸºã¥ãé‡ã¿
                    if abs(diff) > 2.0:  # 200%ä»¥ä¸Šã®å¤‰åŒ–
                        weight = min(abs(diff) * 10, 100)  # ä¸Šé™100
                    else:
                        weight = abs(diff) * 20
                else:  # log_ratio
                    weight = abs(diff) * 30
                
                # ç§‘å­¦ç”¨èªã®è¿½åŠ å¼·èª¿
                if is_science_term:
                    weight *= 1.5
                
                difference_freq[word] = max(weight, 1)  # æœ€å°å€¤1ã‚’ä¿è¨¼
        
        return difference_freq
    
    def generate_difference_wordcloud(self, config):
        """å·®åˆ†ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å–å¾—
            base_source = config.get('base_dataset', 'q2_before')
            compare_source = config.get('compare_dataset', 'q2_after')
            
            # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            base_text = self.base_generator.sample_texts.get(base_source, {}).get('text', '')
            compare_text = self.base_generator.sample_texts.get(compare_source, {}).get('text', '')
            
            if not base_text.strip() or not compare_text.strip():
                return None, "æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™", {}
            
            # é™¤å¤–å˜èªè¨­å®š
            excluded_words = set()
            if config.get('exclude_categories'):
                for category in config.get('exclude_categories', []):
                    if category in self.base_generator.category_stop_words:
                        excluded_words.update(self.base_generator.category_stop_words[category])
            
            if config.get('custom_exclude_words'):
                custom_words = [w.strip() for w in config.get('custom_exclude_words', '').split(',') if w.strip()]
                excluded_words.update(custom_words)
            
            # å˜èªé »åº¦è¨ˆç®—
            base_freq = self.calculate_word_frequencies(base_text, excluded_words)
            compare_freq = self.calculate_word_frequencies(compare_text, excluded_words)
            
            # å·®åˆ†çµ±è¨ˆè¨ˆç®—
            statistics = self.calculate_difference_statistics(base_freq, compare_freq)
            
            # å·®åˆ†é »åº¦è¾æ›¸ç”Ÿæˆ
            difference_freq = self.generate_difference_frequencies(base_freq, compare_freq, config)
            
            if not difference_freq:
                return None, "æœ‰æ„ãªå·®åˆ†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", statistics
            
            # æ–¹å‘æ€§ã«åŸºã¥ãè‰²åˆ†ã‘é–¢æ•°ï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼æº–æ‹ ï¼‰
            def color_func(word, font_size, position, orientation, random_state=None, **kwargs):
                if not hasattr(self, 'word_analysis') or word not in self.word_analysis:
                    return self.difference_colors['common']  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè‰²
                
                analysis = self.word_analysis[word]
                direction = analysis['direction']
                magnitude = analysis['magnitude']
                
                # ç§‘å­¦ç”¨èªã®ç‰¹åˆ¥è‰²ï¼ˆçµ±ä¸€æ„Ÿã®ãŸã‚ãƒ–ãƒ©ã‚¦ãƒ³ï¼‰
                if 'science_level' in analysis:
                    return self.difference_colors['science_highlight']
                
                # æ–¹å‘æ€§ã«åŸºã¥ãè‰²é¸æŠï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼ä½¿ç”¨ï¼‰
                if direction == 'increase':
                    if magnitude > 20:  # å¤§å¹…å¢—åŠ 
                        return self.difference_colors['increase_large']
                    elif magnitude > 5:  # ä¸­ç¨‹åº¦å¢—åŠ 
                        return self.difference_colors['increase_medium']
                    else:  # è»½å¾®å¢—åŠ 
                        return self.difference_colors['increase_small']
                elif direction == 'decrease':
                    if magnitude > 20:  # å¤§å¹…æ¸›å°‘
                        return self.difference_colors['decrease_large']
                    elif magnitude > 5:  # ä¸­ç¨‹åº¦æ¸›å°‘
                        return self.difference_colors['decrease_medium']
                    else:  # è»½å¾®æ¸›å°‘
                        return self.difference_colors['decrease_small']
                else:
                    return self.difference_colors['common']
            
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆæº–å‚™ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°èª¿æ•´ï¼‰
            max_freq = max(difference_freq.values()) if difference_freq else 1
            scale_factor = min(100, max(10, max_freq))
            freq_text = ' '.join([f"{word} " * int((freq / max_freq) * scale_factor) for word, freq in difference_freq.items()])
            
            # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            font_key = config.get('font', 'default')
            font_info = self.base_generator.available_fonts.get(font_key, {})
            font_path = font_info.get('path')
            
            if font_path and not Path(font_path).is_absolute():
                font_path = str(project_root / font_path)
            
            # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—é¸æŠ
            colormap_name = config.get('difference_colormap', 'difference_standard')
            colormap = self.difference_colormaps.get(colormap_name, self.difference_colormaps['difference_standard'])
            
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®šï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æº–æ‹ ï¼‰
            fixed_params = self.base_generator.FIXED_PARAMS
            wordcloud_config = {
                'width': config.get('width', 1000),
                'height': config.get('height', 600),
                'background_color': fixed_params['background_color'],  # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                'max_words': fixed_params['max_words'],                # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                'color_func': color_func,                              # ã‚«ã‚¹ã‚¿ãƒ è‰²åˆ†ã‘é–¢æ•°
                'relative_scaling': fixed_params['relative_scaling'],  # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                'min_font_size': fixed_params['min_font_size'],        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                'max_font_size': fixed_params['max_font_size'],        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                'prefer_horizontal': fixed_params['prefer_horizontal'], # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                'collocations': False,
                'stopwords': set()
            }
            
            if font_path:
                wordcloud_config['font_path'] = font_path
            
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
            wordcloud = WordCloud(**wordcloud_config).generate(freq_text)
            
            # ç”»åƒãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            plt.figure(figsize=(12, 8))
            
            # matplotlibå…¨ä½“ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            font_props = self.get_matplotlib_font_props(font_path)
            if font_props:
                # ã‚¿ã‚¤ãƒˆãƒ«å°‚ç”¨ã§ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ä½¿ç”¨ï¼ˆrcParamsã¯ä½¿ã‚ãªã„ï¼‰
                pass  # font_propsã‚’ã‚¿ã‚¤ãƒˆãƒ«ã§ç›´æ¥ä½¿ç”¨
            
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            
            # æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«è¨­å®šï¼ˆãƒ•ã‚©ãƒ³ãƒˆæŒ‡å®šï¼‰
            title_props = {'fontsize': 16, 'pad': 20}
            if font_props:
                title_props['fontproperties'] = font_props
            plt.title(f'å·®åˆ†åˆ†æ: {base_source} â†’ {compare_source}', **title_props)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            img_buffer = io.BytesIO()
            plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=150)
            img_buffer.seek(0)
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
            plt.close()
            
            return img_base64, None, statistics
            
        except Exception as e:
            logger.error(f"å·®åˆ†ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None, f"ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}", {}

class WordCloudGeneratorV2:
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¯ãƒ©ã‚¹ Ver.2 - å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç‰ˆ"""
    
    # å›ºå®šãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    FIXED_PARAMS = {
        'min_font_size': 24,
        'max_font_size': 174,
        'prefer_horizontal': 0.9,
        'relative_scaling': 0.4,
        'max_words': 140,
        'background_color': '#f8f8f8'
    }
    
    # ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼ï¼ˆWCAG 2.1 Level AAæº–æ‹ ï¼‰
    ACCESSIBLE_COLORS = {
        'orange': '#d06500',  # ã‚ˆã‚Šæ¿ƒã„ã‚ªãƒ¬ãƒ³ã‚¸
        'blue': '#0066cc',    # ã‚ˆã‚Šæ¿ƒã„ãƒ–ãƒ«ãƒ¼
        'brown': '#331a00'    # ãƒ€ãƒ¼ã‚¯ãƒ–ãƒ©ã‚¦ãƒ³
    }
    
    def __init__(self):
        self.fonts_dir = project_root / "fonts"
        self.load_available_fonts()
        self.load_sample_texts()
        self.tokenizer = Tokenizer()
        self.create_accessible_colormaps()
        
        # é™¤å¤–å¯èƒ½ãªæ—¥æœ¬èªã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠå¯èƒ½ï¼‰
        self.default_stop_words = set([
            'ã¦', 'ã«', 'ã‚’', 'ã¯', 'ãŒ', 'ã§', 'ã¨', 'ã—', 'ã‚Œ', 'ã•', 'ã‚ã‚‹', 'ã„ã‚‹', 
            'ã‚‚', 'ã™ã‚‹', 'ã‹ã‚‰', 'ãª', 'ã“ã¨', 'ã§ã™', 'ã ', 'ãŸ', 'ã—ãŸ', 'ã®', 'ã‚ˆã†',
            'ã‚Œã‚‹', 'ãã‚‹', 'ã‚„', 'ãã‚Œ', 'ãã†', 'ãªã„', 'ã‹', 'ã®ã§', 'ã‚ˆ', 'ã¦ã‚‹',
            'ã‚‚ã®', 'ã¿', 'ã¾ãŸ', 'ãã®', 'ã‚ã‚Š', 'ã', 'ã„', 'ã†', 'ã®ã¯', 'ã‚“',
            'ã®ãŒ', 'ã‚‚ã‚“', 'ã©ã†', 'ãªã©', 'ãƒã‚¹', 'ã€‚', 'ã€', 'ï¼ˆ', 'ï¼‰', '(', ')',
            'ã‚ˆã‚Š', 'ã¸', 'ã¾ã§', 'ã‹ã‚‰', 'ã¾ãŸ', 'ã‚‚', 'ãŠ', 'ã¿ãªã•ã‚“', 'ä»Šæ—¥',
            'ã‚ã‚ŠãŒã¨ã†', 'ã”ã–ã„', 'ã¾ã—ãŸ', 'ã¦ãã‚Œ', 'ãã‚Œã‚‹', 'ã¦ãã‚Œã‚‹',
            'ãã ã•ã‚Š', 'ãã ã•ã„', 'ã¾ã›', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„',
            'æ±äº¬é«˜å°‚', 'ã¿ãªã•ã‚“', 'æœ¬å½“', 'ä¸€ç•ª', 'æˆæ¥­', 'ã§ã', 'ã„ã£',
            'ãŠã‚‚ã—ã‚', 'ã™ã”', 'ã‚ˆã‹ã£', 'ã‚ˆã‚Š', 'ã“ã¨', 'ä»Šæ—¥', 'ãã†', 'ãª',
            'ã¦', 'ã‚‹', 'ã‚ˆã†', 'ã«', 'ã§', 'ã¨', 'ã‹ã‚‰', 'ã€‚', 'ã€', 'ãŒ',
            'ãƒŸãƒ³ãƒ', 'ã‚«ãƒ«ã‚·ã‚¦ãƒ ', 'ãƒãƒªã‚¦ãƒ ', 'ãƒªãƒã‚¦ãƒ ', 'ãƒ›ã‚¦é…¸',
            'ãƒ¦ã‚­', 'ã‚¹ã‚±ãƒƒãƒ', 'ã„ã†', 'ã¹ã', 'ã ã£', 'ã¤ã„', 'ã£ãŸ',
            'ã¨ã£', 'ãŠã‚‚ã—ã‚ã„', 'ãã‚Œã„', 'ã™ã”ã„', 'ãªã‚‹', 'ã¿ã‚‹', 'ã„ã',
            'ã‚Œ', 'ãªã‚Š', 'ã‚„ã£', 'ãŸã„', 'ã„ã„', 'ãã‚Œ', 'ãŠ'
        ])
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®é™¤å¤–å˜èªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠå¯èƒ½ï¼‰
        self.category_stop_words = {
            'general': ['ã¿ãªã•ã‚“', 'ä»Šæ—¥', 'ã‚ˆã†', 'ã“ã¨', 'ã‚‚ã®', 'ã¾ã™', 'ã§ã—', 'ã¾ã—'],
            'thanks': ['ã‚ã‚ŠãŒã¨ã†', 'ã”ã–ã„', 'ã¾ã—ãŸ', 'ã¦ãã‚Œ', 'ãã ã•ã‚Š', 'ãã ã•ã„'],
            'school': ['æ±äº¬é«˜å°‚', 'æˆæ¥­', 'å…ˆç”Ÿ', 'å‹‰å¼·', 'å­¦ç¿’'],
            'experiment': ['å®Ÿé¨“', 'è¦³å¯Ÿ', 'ã‚„ã‚Š', 'ã§ã']
        }
    
    def create_accessible_colormaps(self):
        """ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ãªã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’ä½œæˆ"""
        # ãƒ¡ã‚¤ãƒ³ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«3è‰²ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—
        accessible_colors = [
            self.ACCESSIBLE_COLORS['orange'],
            self.ACCESSIBLE_COLORS['blue'],
            self.ACCESSIBLE_COLORS['brown']
        ]
        self.accessible_colormap = ListedColormap(accessible_colors, name='accessible_three')
        
        # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³1: ã‚ªãƒ¬ãƒ³ã‚¸ä¸­å¿ƒ
        orange_focused = [
            self.ACCESSIBLE_COLORS['orange'],
            self.ACCESSIBLE_COLORS['orange'],
            self.ACCESSIBLE_COLORS['blue'],
            self.ACCESSIBLE_COLORS['brown']
        ]
        self.orange_focused = ListedColormap(orange_focused, name='orange_focused')
        
        # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³2: ãƒ–ãƒ«ãƒ¼ä¸­å¿ƒ
        blue_focused = [
            self.ACCESSIBLE_COLORS['blue'],
            self.ACCESSIBLE_COLORS['blue'],
            self.ACCESSIBLE_COLORS['orange'],
            self.ACCESSIBLE_COLORS['brown']
        ]
        self.blue_focused = ListedColormap(blue_focused, name='blue_focused')
        
        # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³3: ãƒãƒ©ãƒ³ã‚¹
        balanced_colors = [
            self.ACCESSIBLE_COLORS['brown'],
            self.ACCESSIBLE_COLORS['orange'],
            self.ACCESSIBLE_COLORS['blue'],
            self.ACCESSIBLE_COLORS['brown']
        ]
        self.balanced_colormap = ListedColormap(balanced_colors, name='balanced')
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—è¾æ›¸
        self.custom_colormaps = {
            'accessible_three': self.accessible_colormap,
            'orange_focused': self.orange_focused,
            'blue_focused': self.blue_focused,
            'balanced': self.balanced_colormap
        }
        
    def load_available_fonts(self):
        """åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿"""
        font_list_path = self.fonts_dir / "font_list.json"
        
        if font_list_path.exists():
            with open(font_list_path, 'r', encoding='utf-8') as f:
                self.available_fonts = json.load(f)
        else:
            self.available_fonts = {
                "default": {
                    "name": "Default",
                    "path": None,
                    "description": "ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"
                }
            }
        
        logger.info(f"åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆæ•°: {len(self.available_fonts)}")
    
    def load_sample_texts(self):
        """å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            data_path = project_root / "data" / "processed" / "all_text_corpus.csv"
            if data_path.exists():
                df = pd.read_csv(data_path)
                
                # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
                comments_text = ' '.join(df[df['category'] == 'æ„Ÿæƒ³æ–‡']['text'].tolist())
                before_text = ' '.join(df[df['category'] == 'Q2ç†ç”±_æˆæ¥­å‰']['text'].tolist())
                after_text = ' '.join(df[df['category'] == 'Q2ç†ç”±_æˆæ¥­å¾Œ']['text'].tolist())
                all_text = ' '.join(df['text'].tolist())
                
                self.sample_texts = {
                    "all_responses": {
                        "name": "å…¨å›ç­”ï¼ˆçµ±åˆï¼‰",
                        "text": all_text
                    },
                    "comments": {
                        "name": "æ„Ÿæƒ³æ–‡ã®ã¿",
                        "text": comments_text
                    },
                    "q2_before": {
                        "name": "æˆæ¥­å‰ï¼ˆãªãœã—ã‚‡ã£ã±ã„ï¼Ÿï¼‰",
                        "text": before_text
                    },
                    "q2_after": {
                        "name": "æˆæ¥­å¾Œï¼ˆãªãœã—ã‚‡ã£ã±ã„ï¼Ÿï¼‰",
                        "text": after_text
                    },
                    "custom": {
                        "name": "ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆ",
                        "text": ""
                    }
                }
                logger.info("å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            else:
                self._load_default_texts()
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self._load_default_texts()
    
    def _load_default_texts(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ"""
        self.sample_texts = {
            "science_education": {
                "name": "ç§‘å­¦æ•™è‚²ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰",
                "text": """æ±äº¬å·¥æ¥­å¤§å­¦ å‡ºå‰æˆæ¥­ ãƒŠãƒˆãƒªã‚¦ãƒ  å¡©åŒ–ãƒŠãƒˆãƒªã‚¦ãƒ  ç‚è‰²åå¿œ å®Ÿé¨“ è¦³å¯Ÿ ç§‘å­¦ å­¦ç¿’ 
                         é¢ç™½ã„ ã™ã”ã„ ãã‚Œã„ ç™ºè¦‹ ç†è§£ çŸ¥è­˜ ç ”ç©¶ ä½“é¨“ æ„Ÿå‹• ã³ã£ãã‚Š"""
            },
            "custom": {
                "name": "ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆ",
                "text": ""
            }
        }
    
    def tokenize_japanese(self, text, excluded_words=None):
        """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ï¼ˆé™¤å¤–å˜èªã‚’è€ƒæ…®ï¼‰"""
        # é™¤å¤–å˜èªã‚»ãƒƒãƒˆã‚’ä½œæˆ
        stop_words = self.default_stop_words.copy()
        if excluded_words:
            stop_words.update(excluded_words)
        
        # å˜èªã‚’æŠ½å‡ºï¼ˆåè©ã€å‹•è©ã€å½¢å®¹è©ã€å‰¯è©ã®ã¿ï¼‰
        words = []
        for token in self.tokenizer.tokenize(text):
            part_of_speech = token.part_of_speech.split(',')[0]
            if part_of_speech in ['åè©', 'å‹•è©', 'å½¢å®¹è©', 'å‰¯è©']:
                # åŸºæœ¬å½¢ã‚’å–å¾—
                base_form = token.base_form
                word = base_form if base_form != '*' else token.surface
                
                # 2æ–‡å­—ä»¥ä¸Šã‹ã¤ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã§ãªã„å˜èªã®ã¿ã‚’è¿½åŠ 
                if len(word) >= 2 and word not in stop_words:
                    words.append(word)
        return ' '.join(words)
    
    def generate_wordcloud(self, config):
        """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            text_key = config.get('text_source', 'all_responses')
            if text_key == 'custom':
                text = config.get('custom_text', '')
            else:
                text = self.sample_texts.get(text_key, {}).get('text', '')
            
            if not text.strip():
                return None, "ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"
            
            # é™¤å¤–å˜èªã®åé›†
            excluded_words = set()
            if config.get('exclude_categories'):
                for category in config.get('exclude_categories', []):
                    if category in self.category_stop_words:
                        excluded_words.update(self.category_stop_words[category])
            
            # ã‚«ã‚¹ã‚¿ãƒ é™¤å¤–å˜èªã‚’è¿½åŠ 
            if config.get('custom_exclude_words'):
                custom_words = [w.strip() for w in config.get('custom_exclude_words', '').split(',') if w.strip()]
                excluded_words.update(custom_words)
            
            # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ï¼ˆé™¤å¤–å˜èªã‚’é©ç”¨ï¼‰
            tokenized_text = self.tokenize_japanese(text, excluded_words)
            
            # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            font_key = config.get('font', 'default')
            font_info = self.available_fonts.get(font_key, {})
            font_path = font_info.get('path')
            
            # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
            if font_path and not Path(font_path).is_absolute():
                font_path = str(project_root / font_path)
            
            # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’é¸æŠï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã®ã¿ï¼‰
            colormap_name = config.get('colormap', 'accessible_three')
            colormap = self.custom_colormaps.get(colormap_name, self.accessible_colormap)
            
            # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®š
            wordcloud_config = {
                'width': config.get('width', 1000),
                'height': config.get('height', 600),
                'background_color': self.FIXED_PARAMS['background_color'],
                'max_words': self.FIXED_PARAMS['max_words'],
                'colormap': colormap,
                'relative_scaling': self.FIXED_PARAMS['relative_scaling'],
                'min_font_size': self.FIXED_PARAMS['min_font_size'],
                'max_font_size': self.FIXED_PARAMS['max_font_size'],
                'prefer_horizontal': self.FIXED_PARAMS['prefer_horizontal'],
                'collocations': False,
                'regexp': r'[\w]+',
                'include_numbers': False,
                'normalize_plurals': False,
                'stopwords': set()  # æ—¢ã«é™¤å¤–å‡¦ç†æ¸ˆã¿ãªã®ã§ç©ºã‚»ãƒƒãƒˆ
            }
            
            if font_path:
                wordcloud_config['font_path'] = font_path
            
            # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
            wordcloud = WordCloud(**wordcloud_config).generate(tokenized_text)
            
            # ç”»åƒå¤‰æ›
            plt.figure(figsize=(12, 6))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.tight_layout(pad=0)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            img_buffer = io.BytesIO()
            plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            img_buffer.seek(0)
            plt.close()
            
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            
            return img_base64, None
            
        except Exception as e:
            logger.error(f"ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None, str(e)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
generator = WordCloudGeneratorV2()
difference_generator = DifferenceWordCloudGenerator(generator)

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ï¼ˆVer.2ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰"""
    return render_template('index_v2.html')

@app.route('/api/fonts')
def get_fonts():
    """åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆä¸€è¦§å–å¾—"""
    return jsonify({
        'fonts': generator.available_fonts,
        'count': len(generator.available_fonts)
    })

@app.route('/api/sample-texts')
def get_sample_texts():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆä¸€è¦§å–å¾—"""
    return jsonify({
        'texts': generator.sample_texts
    })

@app.route('/api/generate', methods=['POST'])
def generate_wordcloud():
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”ŸæˆAPI"""
    try:
        config = request.json
        
        img_base64, error = generator.generate_wordcloud(config)
        
        if error:
            return jsonify({
                'success': False,
                'error': error
            }), 400
        
        return jsonify({
            'success': True,
            'image': img_base64,
            'config': config,
            'fixed_params': generator.FIXED_PARAMS
        })
        
    except Exception as e:
        logger.error(f"API ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/fixed-params')
def get_fixed_params():
    """å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—"""
    return jsonify({
        'fixed_params': generator.FIXED_PARAMS,
        'accessible_colors': generator.ACCESSIBLE_COLORS
    })

@app.route('/api/stop-words')
def get_stop_words():
    """é™¤å¤–å¯èƒ½ãªå˜èªã‚«ãƒ†ã‚´ãƒªãƒ¼å–å¾—"""
    return jsonify({
        'categories': {
            'general': {
                'name': 'ä¸€èˆ¬çš„ãªå˜èª',
                'words': list(generator.category_stop_words['general'])
            },
            'thanks': {
                'name': 'æ„Ÿè¬ã®è¡¨ç¾',
                'words': list(generator.category_stop_words['thanks'])
            },
            'school': {
                'name': 'å­¦æ ¡é–¢é€£',
                'words': list(generator.category_stop_words['school'])
            },
            'experiment': {
                'name': 'å®Ÿé¨“é–¢é€£',
                'words': list(generator.category_stop_words['experiment'])
            }
        }
    })

@app.route('/api/colormaps')
def get_colormaps():
    """åˆ©ç”¨å¯èƒ½ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—å–å¾—ï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ç‰ˆã®ã¿ï¼‰"""
    accessible_maps = [
        'accessible_three',
        'orange_focused',
        'blue_focused',
        'balanced'
    ]
    
    return jsonify({'colormaps': accessible_maps})

@app.route('/api/export-config', methods=['POST'])
def export_config():
    """è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        config = request.json
        
        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        full_config = config.copy()
        full_config['fixed_params'] = generator.FIXED_PARAMS
        full_config['version'] = 'v2_accessible'
        
        # è¨­å®šã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        exports_dir = project_root / "outputs" / "wordcloud_configs"
        exports_dir.mkdir(parents=True, exist_ok=True)
        
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"wordcloud_config_v2_{timestamp}.json"
        config_path = exports_dir / filename
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(full_config, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'filename': filename,
            'path': str(config_path)
        })
        
    except Exception as e:
        logger.error(f"è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/difference-generate', methods=['POST'])
def generate_difference_wordcloud():
    """å·®åˆ†ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”ŸæˆAPI"""
    try:
        config = request.json
        
        img_base64, error, statistics = difference_generator.generate_difference_wordcloud(config)
        
        if error:
            return jsonify({
                'success': False,
                'error': error,
                'statistics': statistics
            }), 400
        
        return jsonify({
            'success': True,
            'image': img_base64,
            'config': config,
            'statistics': statistics,
            'type': 'difference'
        })
        
    except Exception as e:
        logger.error(f"å·®åˆ†API ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'statistics': {}
        }), 500

@app.route('/api/difference-colormaps')
def get_difference_colormaps():
    """å·®åˆ†ç”¨ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—å–å¾—"""
    return jsonify({
        'colormaps': list(difference_generator.difference_colormaps.keys()),
        'colors': difference_generator.difference_colors
    })

@app.route('/api/science-terms')
def get_science_terms():
    """ç§‘å­¦ç”¨èªãƒªã‚¹ãƒˆå–å¾—"""
    return jsonify({
        'science_terms': difference_generator.science_terms
    })

if __name__ == '__main__':
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿
    logs_dir = project_root / "logs"
    logs_dir.mkdir(exist_ok=True)
    
    print("ğŸŒ¨ æ±äº¬é«˜å°‚ å‡ºå‰æˆæ¥­åˆ†æ - ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ„ãƒ¼ãƒ« Ver.2")
    print("=" * 60)
    print("ğŸ¯ å˜èªé™¤å¤–ãƒ†ã‚¹ãƒˆç‰ˆï¼ˆå›ºå®šãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰")
    print(f"ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹URL: http://localhost:5002")
    print(f"ğŸ“ ãƒ•ã‚©ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {generator.fonts_dir}")
    print(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆæ•°: {len(generator.available_fonts)}")
    print("â™¿ ã‚¢ã‚¯ã‚»ã‚·ãƒ–ãƒ«ã‚«ãƒ©ãƒ¼: ã‚ªãƒ¬ãƒ³ã‚¸(#d06500)ãƒ»ãƒ–ãƒ«ãƒ¼(#0066cc)ãƒ»ãƒ–ãƒ©ã‚¦ãƒ³(#331a00)")
    print("ğŸ”§ å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for key, value in generator.FIXED_PARAMS.items():
        print(f"   - {key}: {value}")
    print("=" * 60)
    
    # Flaskã‚¢ãƒ—ãƒªå®Ÿè¡Œï¼ˆãƒãƒ¼ãƒˆ5002ï¼‰
    app.run(debug=True, host='0.0.0.0', port=5002)